{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b28c4e",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "In this project, we compare eight machine-learning algorithms for time-series forecasting of synthetic equity returns, derived from lagged stock characteristics and macroeconomic factors. To ensure clean, modular, and reusable code, we adopt an object-oriented design:\n",
    "\n",
    "    All regressors inherit from a single BaseRegressor class, which centralizes\n",
    "\n",
    "        data preprocessing (scaling),\n",
    "\n",
    "        training and hyperparameter tuning,\n",
    "\n",
    "        prediction and evaluation metrics (out-of-sample R², zero-return R², cross-sectional R², MSE),\n",
    "\n",
    "        diagnostic plotting, and\n",
    "\n",
    "        feature‐importance extraction.\n",
    "\n",
    "    Each specific model (OLS, Elastic Net, PCR, PLS, spline-based GLM, Random Forest, Gradient Boosting, Neural Network) only needs to implement its own pipeline and—where needed—custom training logic. This inheritance structure drastically reduces boilerplate, makes it straightforward to add or extend models, and keeps our analysis code concise.\n",
    "\n",
    "Beyond raw predictive performance, we also:\n",
    "\n",
    "    Benchmark forecasts via the Diebold–Mariano test for statistically comparing model errors,\n",
    "\n",
    "    Visualize feature importances across models with a unified heatmap, and\n",
    "\n",
    "    Assess economic value through a decile portfolio analysis, ranking stocks by predicted return and comparing realized Sharpe ratios.\n",
    "\n",
    "This end-to-end, OOP-driven framework delivers both rigorous model evaluation and actionable financial insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5993f45",
   "metadata": {},
   "source": [
    "Import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_processing import split_data\n",
    "\n",
    "from models.linear_models.ordinary_least_squares_regression import OLSModel\n",
    "from models.linear_models.elastic_net_regression import ElasticNetModel\n",
    "from models.linear_models.principal_component_regression import PCRModel\n",
    "from models.linear_models.partial_least_squares_regression import PLSModel\n",
    "from models.linear_models.generalized_linear_model import GLMModel\n",
    "from models.non_linear_models.neural_network import NeuralNetworkModel\n",
    "from models.non_linear_models.gradient_boosting import GradientBoostingModel\n",
    "from models.non_linear_models.random_forest import RandomForestModel\n",
    "\n",
    "from utility.variable_importance import drop_feature_importance\n",
    "from utility.prediction_wrapper import PredictionWrapper\n",
    "from utility.diebold_mariano_test import diebold_mariano\n",
    "from utility.decile_portfolio import DecilePortfolioAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc735a1",
   "metadata": {},
   "source": [
    "Part 1 & 2: Data Generation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46256690",
   "metadata": {},
   "source": [
    "Part 3: Model Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OLS Model Training and Evaluation ---\n",
    "ols_model = OLSModel(n_stocks=10)\n",
    "ols_model.train(X_train, y_train)\n",
    "\n",
    "# --- ElasticNet Model Tuning ---\n",
    "elastic_net_model = ElasticNetModel(n_stocks=10)\n",
    "elastic_net_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- Principal Component Regression (PCR) ---\n",
    "pcr_model = PCRModel(n_stocks=10)\n",
    "pcr_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- Partial Least Squares Regression (PLS) ---\n",
    "pls_model = PLSModel(n_stocks=10)\n",
    "pls_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- Generalized Linear Model (Spline Transformation + ElasticNet) ---\n",
    "glm = GLMModel(n_stocks=10)\n",
    "glm.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- non-linear models ---\n",
    "\n",
    "# --- Neural Network Model ---\n",
    "nn_model = NeuralNetworkModel(n_stocks=10)\n",
    "nn_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- Gradient Boosting Regressor ---\n",
    "gradient_boosting_model = GradientBoostingModel(n_stocks=10)\n",
    "gradient_boosting_model.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# --- Random Forest Regressor ---\n",
    "random_forest_model = RandomForestModel(n_stocks=10)\n",
    "random_forest_model.train(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255f12f",
   "metadata": {},
   "source": [
    "Part 4: Prediction Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ca379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Modelle im Dictionary sammeln\n",
    "models = {\n",
    "    'OLS':                ols_model,\n",
    "    'ElasticNet':         elastic_net_model,\n",
    "    'PCR':                pcr_model,\n",
    "    'PLS':                pls_model,\n",
    "    'GLM':                glm,\n",
    "    'NeuralNetwork':      nn_model,\n",
    "    'GradientBoosting':   gradient_boosting_model,\n",
    "    'RandomForest':       random_forest_model\n",
    "}\n",
    "\n",
    "# Wrapper instanziieren (alle Modelle müssen bereits trainiert sein)\n",
    "wrapper = PredictionWrapper(models)\n",
    "\n",
    "# Auf dem Test-Set alle Vorhersagen sammeln\n",
    "df_preds = wrapper.predict(X_test)\n",
    "print(df_preds.head())   # zeigt die ersten Zeilen mit 8 Spalten\n",
    "\n",
    "# Bei Bedarf direkt z.B. in Part 6:\n",
    "# Out-of-Sample R² für alle Modelle in einer Schleife\n",
    "for name in df_preds.columns:\n",
    "    y_pred = df_preds[name].values\n",
    "    metrics = models[name].evaluate(X_test, y_test)\n",
    "    models[name].print_summary(f\"{name} Test\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c2b65",
   "metadata": {},
   "source": [
    "Part 5: Full-Sample Time Series Plots - to see the predictions vs. actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f228eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model.plot_diagnostics(X_test, y_test)\n",
    "elastic_net_model.plot_diagnostics(X_test, y_test)\n",
    "pcr_model.plot_diagnostics(X_test, y_test)\n",
    "pls_model.plot_diagnostics(X_test, y_test)\n",
    "glm.plot_diagnostics(X_test, y_test)\n",
    "nn_model.plot_diagnostics(X_test, y_test)\n",
    "gradient_boosting_model.plot_diagnostics(X_test, y_test)\n",
    "random_forest_model.plot_diagnostics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d750712",
   "metadata": {},
   "source": [
    "Part 6: Out-of-Sample R² Results Table - to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808239a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = ols_model.evaluate(X_val, y_val)\n",
    "ols_model.print_summary(\"OLS Validation\", val_metrics)\n",
    "test_metrics = ols_model.evaluate(X_test, y_test)\n",
    "ols_model.print_summary(\"OLS Test\", test_metrics)\n",
    "ols_model.print_feature_importance(top_n=10)\n",
    "\n",
    "elastic_net_model.print_hyperparameters()\n",
    "val_metrics = elastic_net_model.evaluate(X_val, y_val)\n",
    "elastic_net_model.print_summary(\"ElasticNet Validation\", val_metrics)\n",
    "test_metrics = elastic_net_model.evaluate(X_test, y_test)\n",
    "elastic_net_model.print_summary(\"ElasticNet Test\", test_metrics)\n",
    "elastic_net_model.print_feature_importance(top_n=10)\n",
    "\n",
    "pcr_model.print_best_k()\n",
    "val_metrics = pcr_model.evaluate(X_val, y_val)\n",
    "pcr_model.print_summary(\"PCR Validation\", val_metrics)\n",
    "test_metrics = pcr_model.evaluate(X_test, y_test)\n",
    "pcr_model.print_summary(\"PCR Test\", test_metrics)\n",
    "pcr_model.print_feature_importance(top_n=10)\n",
    "\n",
    "pls_model.print_best_k()\n",
    "val_metrics = pls_model.evaluate(X_val, y_val)\n",
    "pls_model.print_summary(\"PLS Validation\", val_metrics)\n",
    "test_metrics = pls_model.evaluate(X_test, y_test)\n",
    "pls_model.print_summary(\"PLS Test\", test_metrics)\n",
    "pls_model.print_feature_importance(top_n=10)\n",
    "\n",
    "glm.print_hyperparameters()\n",
    "val_metrics = glm.evaluate(X_val, y_val)\n",
    "glm.print_summary(\"GLM Validation\", val_metrics)\n",
    "test_metrics = glm.evaluate(X_test, y_test)\n",
    "glm.print_summary(\"GLM Test\", test_metrics)\n",
    "glm.print_feature_importance()\n",
    "\n",
    "nn_model.print_architecture()\n",
    "val_metrics = nn_model.evaluate(X_val, y_val)\n",
    "nn_model.print_summary(\"Neural Network Validation\", val_metrics)\n",
    "test_metrics = nn_model.evaluate(X_test, y_test)\n",
    "nn_model.print_summary(\"Neural Network Test\", test_metrics)\n",
    "\n",
    "gradient_boosting_model.print_hyperparameters()\n",
    "val_metrics = gradient_boosting_model.evaluate(X_val, y_val)\n",
    "gradient_boosting_model.print_summary(\"Gradient Boosting Validation\", val_metrics)\n",
    "test_metrics = gradient_boosting_model.evaluate(X_test, y_test)\n",
    "gradient_boosting_model.print_summary(\"Gradient Boosting Test\", test_metrics)\n",
    "gradient_boosting_model.print_feature_importance(top_n=10)\n",
    "\n",
    "val_metrics = random_forest_model.evaluate(X_val, y_val)\n",
    "random_forest_model.print_summary(\"Random Forest Validation\", val_metrics)\n",
    "test_metrics = random_forest_model.evaluate(X_test, y_test)\n",
    "random_forest_model.print_summary(\"Random Forest Test\", test_metrics)\n",
    "random_forest_model.print_feature_importance(top_n=10)\n",
    "random_forest_model.print_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47576a1d",
   "metadata": {},
   "source": [
    "Part 7: Diebold-Mariano Test Statistics - to compare model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true, y_pred_ols, y_pred_en jeweils aus deinen Modellen\n",
    "\n",
    "# Nachdem Du alle Modelle trainiert und ihre Vorhersagen erzeugt hast:\n",
    "\n",
    "\n",
    "# 1) Vorhersagen auf dem Test-Set\n",
    "y_pred_ols   = ols_model.predict(X_test)\n",
    "y_pred_en    = elastic_net_model.predict(X_test)\n",
    "y_pred_pcr   = pcr_model.predict(X_test)\n",
    "y_pred_pls   = pls_model.predict(X_test)\n",
    "y_pred_glm   = glm.predict(X_test)\n",
    "y_pred_rf    = random_forest_model.predict(X_test)\n",
    "y_pred_gb    = gradient_boosting_model.predict(X_test)\n",
    "y_pred_nn    = nn_model.predict(X_test)\n",
    "\n",
    "# 2) Ensembles\n",
    "linear_preds    = np.vstack([y_pred_ols, y_pred_en, y_pred_pcr, y_pred_pls, y_pred_glm]).mean(axis=0)\n",
    "nonlin_preds    = np.vstack([y_pred_rf, y_pred_gb, y_pred_nn]).mean(axis=0)\n",
    "\n",
    "# 3) Define DM comparisons\n",
    "comparisons = [\n",
    "    (\"OLS\",             \"ElasticNet\",    y_pred_ols, linear_preds := y_pred_en),    # 1\n",
    "    (\"OLS\",             \"PCR\",           y_pred_ols, y_pred_pcr),                   # 2\n",
    "    (\"OLS\",             \"PLS\",           y_pred_ols, y_pred_pls),                   # 3\n",
    "    (\"OLS\",             \"GLM\",           y_pred_ols, y_pred_glm),                   # 4\n",
    "    (\"OLS\",             \"RandomForest\",  y_pred_ols, y_pred_rf),                    # 5\n",
    "    (\"OLS\",             \"GradientBoosting\", y_pred_ols, y_pred_gb),                 # 6\n",
    "    (\"OLS\",             \"NeuralNetwork\", y_pred_ols, y_pred_nn),                   # 7\n",
    "    (\"LinearEnsemble\",  \"NonlinearEnsemble\", linear_preds, nonlin_preds),           # 8\n",
    "    (\"RandomForest\",    \"ElasticNet\",    y_pred_rf,    y_pred_en),                 # 9\n",
    "    (\"RandomForest\",    \"NeuralNetwork\", y_pred_rf,    y_pred_nn),                 # 10\n",
    "    (\"ElasticNet\",      \"NeuralNetwork\", y_pred_en,    y_pred_nn),                 # 11\n",
    "]\n",
    "\n",
    "# 4) Ausführen und ausgeben\n",
    "for name1, name2, pred1, pred2 in comparisons:\n",
    "    dm_stat, p_val = diebold_mariano(y_test, pred1, pred2, h=1, loss='mse')\n",
    "    print(f\"{name1:20s} vs. {name2:20s} → DM = {dm_stat:7.3f}, p-value = {p_val:7.3f}\")\n",
    "\n",
    "dm_stat, p_val = diebold_mariano(y_test, y_pred_ols, y_pred_en, h=1, loss='mse')\n",
    "print(f\"DM-Statistic: {dm_stat:.3f}, p-value: {p_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fbd40",
   "metadata": {},
   "source": [
    "Part 8: Variable Importance Calculations & Heatmaps - to understand feature importance ( to see which features are more important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angenommen, feature_names ist z.B.:\n",
    "feature_names = [f\"feat_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Berechne Importances für alle Modelle\n",
    "feature_names = [f\"feat_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Beispiel für ElasticNet:\n",
    "vi_en = drop_feature_importance(\n",
    "    elastic_net_model,                      # schon gefittetes Modell\n",
    "    {'n_stocks':10},                        # + ggf. alle __init__-Args (ElasticNetModel zieht seine propre alphas/l1_ratios intern)\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    X_test,  y_test,\n",
    "    feature_names\n",
    ")\n",
    "\n",
    "# Für andere Modelle analog:\n",
    "vi_rf = drop_feature_importance(random_forest_model, {'n_stocks':10}, \n",
    "                                X_train, y_train, X_val, y_val, X_test, y_test, feature_names)\n",
    "\n",
    "# Dann Heatmap:\n",
    "df_vi = pd.concat({\n",
    "    'ElasticNet': vi_en,\n",
    "    'RandomForest': vi_rf,\n",
    "    # ... weitere Modelle\n",
    "}, axis=1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_vi, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "plt.title(\"Variable Importance (Drop in R²)\")\n",
    "plt.xlabel(\"Modell\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b26ea",
   "metadata": {},
   "source": [
    "Part 9: Auxiliary Functions and Decile Portfolio Analysis - to analyze model performance across deciles - to compare predicted vs actual  sharpe ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziieren mit der Anzahl Stocks pro Periode\n",
    "decile_analyzer = DecilePortfolioAnalysis(n_stocks=10)\n",
    "\n",
    "# Für jedes Modell\n",
    "df_ols = decile_analyzer.compute_decile_returns(y_pred_ols, y_test)\n",
    "decile_analyzer.plot_sharpe(df_ols, title=\"OLS Decile Sharpe Ratios\")\n",
    "\n",
    "df_rf = decile_analyzer.compute_decile_returns(y_pred_rf, y_test)\n",
    "decile_analyzer.plot_sharpe(df_rf, title=\"RandomForest Decile Sharpe Ratios\")\n",
    "\n",
    "# Und so weiter für alle Modelle…"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meinprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
